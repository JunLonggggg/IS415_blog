---
title: "hands-on exercise 7"
description: |
  In this hands on exercise, we learn to use global statistics for spatial autocorrelation, such as Moran's I and Geary's C, going more in-depth using local Moran's I and local Geary's C. Lastly, the global Getis-Ord's G stats to illustrate correlation using nearest neighbor's distance.
author:
  - name: Toh Jun Long
    url: https://linkedin.com/in/tohjunlong
date: 09-26-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE, eval=TRUE, echo=TRUE, message=FALSE,error=FALSE, fig.retina=3}
knitr::opts_chunk$set(echo = FALSE)
```

Importing the relevant packages:

sf for handling geospatial data

spdep for computing spatial weights, global and local autocorrelation statistics.

tmap for plotting

tidyverse for data wrangling

```{r}
packages = c('sf', 'spdep', 'tmap', 'tidyverse')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
```

Importing the Hunan geospatial file

```{r}
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

Importing Hunan Aspatial file

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

Looking at the geospatial map for an idea of what it looks like

```{r}
tm_shape(hunan) +
  tm_polygons()
```

```{r}
hunan <- left_join(hunan,hunan2012)
```

```{r}
basemap <- tm_shape(hunan) +
  tm_polygons() +
  tm_text("NAME_3", size=0.5)

gdppc <- qtm(hunan, "GDPPC")
tmap_arrange(basemap, gdppc, asp=1, ncol=2)
```


Global Spatial Autocorrelation:


Constructing spatial weights of the study area.

Spatial weights are used to define the neighbourhood relationships between geographical units in the study area.

poly2nb() computes contiguity weight matrices.
Using previous lesson's knowledge of the "queen" and "rook" to define neighbours. In this case, we identify neighbours using "queen".

1. create neighbor list
2. compute the contiguity

```{r}
wm_q <- poly2nb(hunan, queen=TRUE)
summary(wm_q)
```

if you set the queen = True, it is actually not changed since the default adjacency configuration is in queens. Setting it to false will then set the adjacency config to "Rook" method.

How to we want to do the weight matrix?
Row standardization or binary.

#### Row-standardised weights matrix:

Goal is to assign weights to each neighboring polygon. Assigning equal weight of 1/(# of neighbours). 

The drawback of such assignment style is that it may cause under or over estimation of the spatial autocorrelation.

Possible exploration: style = B

```{r}
rswm_q <- nb2listw(wm_q, style="W", zero.policy = TRUE)
rswm_q
```

zero.policy is used to allow non-neighbours. Good for when we are not sure if there are missing neighbours.

## Global Spatial Autocorrelation: Moran's I test

we can set the alternative hypothesis using the parameter, alternative = "<string>".

if we happen to be using ranked data (ordinal), we should change the "rank" parameter to True.

```{r}
moran.test(hunan$GDPPC, listw=rswm_q, zero.policy = TRUE, na.action=na.omit)
```

p-value is small, thus we can infer that this is statistically significant, reject null hypothesis. Z value is 0.301 (3 s.f.) which is positive, means that observations around the within the study area are likely to have small degree of similarity. Signs of clustering.

### Monte Carlo's Moran's I

The start seed is fixed such that the simulation generated is standardized.

```{r}
set.seed(1234)
bperm= moran.mc(hunan$GDPPC, listw=rswm_q, nsim=999, zero.policy = TRUE, na.action=na.omit)
bperm
```

Observations are likely to have small degree of similarity and relatively weak.

Visualizing Monte Carlo's Moran's I

```{r}
mean(bperm$res[1:999])
```

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

bperm -> permutatiton, plot the residue of the permutation. Our aim is to confirm the central limit theorem: if we have large sample, the sample should resemble a normal distribution.

At p-value of 0.01, it may not be a confident decision to reject the null hypothesis.  

```{r}
hist(bperm$res, freq=TRUE, breaks=20, xlab="Simulated Moran's I")
abline(v=0, col="red")
```

using ggplot (kiv)

```{r}
#ggplot(bperm$res, aes = (x ="") + geom_histogram())
```

## Geary's C test

```{r}
geary.test(hunan$GDPPC, listw=rswm_q)
```

p-value is small, thus we can infer that this is statistically significant, reject null hypothesis. Z value is 0.691 (3 s.f.) which is smaller than 1, means that observations around the within the study area are likely to have small degree of similarity.

```{r}
set.seed(1234)
bperm=geary.mc(hunan$GDPPC, listw=rswm_q, nsim=999)
bperm  
```

```{r}
mean(bperm$res[1:999])
```

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res, freq=TRUE, breaks=20, xlab="Simulated Geary c")
abline(v=1, col="red") 
```

### Spatial Correlation

Correlogram of the different orders, from 1st order to 6th order.

most important parameter is the order, the method and the style.

I method if moran's I.

This is not the normal plot from base graphic, this is specifically for correlogram.

```{r}
MI_corr <- sp.correlogram(wm_q, hunan$GDPPC, order=6, method="I", style="B")
plot(MI_corr)
```

```{r}
print(MI_corr)
```

lag 4 is not statistically significant, this is greater than any of the commonly used alpha value. the stars signifies that the lag 4 does not have enough statistical evidence to reject null hypothesis.

after finding out that there are clustering, we need to find out where is the cluster, hence to use local tests.

```{r}
GC_corr <- sp.correlogram(wm_q, hunan$GDPPC, order=6, method="C", style="W")
plot(GC_corr)
```

Cluster and Outlier analysis

```{r}
fips <- order(hunan$County)
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

```{r}
printCoefmat(data.frame(localMI[fips,], row.names=hunan$County[fips]), check.names=FALSE)
```

positive score indicates clustering while negative score indicates outlier.

```{r}
hunan.localMI <- cbind(hunan,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

Mapping Local Moran's I values

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

We can only see the postive correlation and signs of clustering from the plot above. We should look at the plot of p-value to have the confidence to conclude that there are signs of clustering

mapping local Moran's I p-values

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

Mapping both local Moran's I and p values to draw conclusion.

```{r}
localMI.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

Decompose the relationship.



### Creating Local Indication of Spatial Assocation (LISA):

plotting Moran scatterplot

```{r}
nci <- moran.plot(hunan$GDPPC, rswm_q,
                  labels=as.character(hunan$County), 
                  xlab="GDPPC 2012", 
                  ylab="Spatially Lag GDPPC 2012")

```

Need to scale such that the autocorrelation around 0.

```{r}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>% as.vector 
```



```{r}
nci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,
                   labels=as.character(hunan$County),
                   xlab="z-GDPPC 2012", 
                   ylab="Spatially Lag z-GDPPC 2012")
```
we need to standardize such that z shows the target county, while w are surrounding counties.

negative autocorrelation are likely outliers.


Preparing LISA map classes:

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
```

```{r}
DV <- hunan$GDPPC - mean(hunan$GDPPC) 
```

```{r}
C_mI <- localMI[,1] - mean(localMI[,1])
```

```{r}
signif <- 0.05
```

```{r}
quadrant[DV >0 & C_mI>0] <- 4      
quadrant[DV <0 & C_mI<0] <- 1      
quadrant[DV <0 & C_mI>0] <- 2
quadrant[DV >0 & C_mI<0] <- 3
```


```{r}
quadrant[localMI[,5]>signif] <- 0
```

Combined code chunk to identify, high-high, low-low, low-high, high-low and insignificant Moran

Should revisit the code below.

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
DV <- hunan$GDPPC - mean(hunan$GDPPC)     
C_mI <- localMI[,1] - mean(localMI[,1])    
signif <- 0.05       
quadrant[DV >0 & C_mI>0] <- 4      
quadrant[DV <0 & C_mI<0] <- 1      
quadrant[DV <0 & C_mI>0] <- 2
quadrant[DV >0 & C_mI<0] <- 3
quadrant[localMI[,5]>signif] <- 0
```

Plot LISA Map

```{r}
hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

```{r}
gdppc <- qtm(hunan, "GDPPC")

hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(gdppc, LISAmap, asp=1, ncol=2)
```

Looking at the original value, the county with "low-low" among the "high-high". there is improvement to check on why is the county classified wrongly.Have to change the above code more.

### Hot Spot and Cold Spot Area analysis

Only if there is no negative value. If there are negative value, then we cannpt use the Getis-Ord G stats.

2 types:
+ fixed
+ adaptive

Getis and Ord's G-stats

Reduce computation time by breaking down to lat and long, also to avoid the centroid to be placed wrongly.

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

```{r}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

```{r}
coords <- cbind(longitude, latitude)
```

```{r}
#coords <- coordinates(hunan)
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```


Computing fixed distance weight matrix

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

```{r}
wm62_lw <- nb2listw(wm_d62, style = 'B')
summary(wm62_lw)
```

Fix the number of nearest neighbor

```{r}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

```{r}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

Computing Gi Stats

```{r}
fips <- order(hunan$County)
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```

```{r}
hunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

Mapping Gi Stats with fixed distance weights

```{r}
gdppc <- qtm(hunan, "GDPPC")

Gimap <-tm_shape(hunan.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```

No outliers can be seen here, hot spots are where highly correlated. Likely because of factors such as travel corridor etc.

#### Using adaptive distance

```{r}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

```{r}
gdppc <- qtm(hunan, "GDPPC")

Gimap <- tm_shape(hunan.gi) +
  tm_fill(col = "gstat_adaptive", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```

The results are more homogenous. 
